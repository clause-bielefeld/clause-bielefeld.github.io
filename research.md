---
layout: page
title: Research
permalink: /research/
---

## Awards and accolades
- Raha, Sina, Özge and Judith received an outstanding paper award at the [BabyLM Challenge & Workshop 2025](https://babylm.github.io/index.html) for their paper  [https://aclanthology.org/2025.babylm-main.4/](https://aclanthology.org/2025.babylm-main.4/)
- Simeon & Sina received the best paper award at [INLG 2024](https://2024.inlgmeeting.org/awards.html) for their paper [https://aclanthology.org/2024.inlg-main.29/](https://aclanthology.org/2024.inlg-main.29/)

## Recent publications

- Alacam, Ö., Hoeken, S., & Zarrieß, S. (2024). Eyes don’t lie: Subjective hate annotation and detection with gaze. Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, 187–205. https://doi.org/10.18653/v1/2024.emnlp-main.11

- Brinner, M., & Zarrieß, S. (2025). Efficient scientific full text classification: The case of eicat impact assessments. In V. Basile, C. Bosco, F. Grasso, M. O. Ibrohim, M. Skeppstedt, & M. Stede (Hrsg.), Proceedings of the 1st Workshop on Ecology, Environment, and Natural Language Processing (NLP4Ecology2025) (S. 94–103). University of Tartu Library. https://aclanthology.org/2025.nlp4ecology-1.20/

- Bunzeck, B., Duran, D., & Zarrieß, S. (2025). Do construction distributions shape formal language learning in german babylms? Proceedings of the 29th Conference on Computational Natural Language Learning, 169–186. https://doi.org/10.18653/v1/2025.conll-1.12

- Bunzeck, B., & Zarrieß, S. (2025). Subword models struggle with word learning, but surprisal hides it. Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), 286–300. https://doi.org/10.18653/v1/2025.acl-short.24

- Hoeken, S., Zarrieß, S., & Alacam, Ö. (2024). Hateful word in context classification. Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, 172–186. https://doi.org/10.18653/v1/2024.emnlp-main.10

- Junker, S., Ali, M., Koch, L., Zarrieß, S., & Buschmeier, H. (2025). Are multimodal large language models pragmatically competent listeners in simple reference resolution tasks? Findings of the Association for Computational Linguistics: ACL 2025, 24101–24109. https://doi.org/10.18653/v1/2025.findings-acl.1236

- Lachenmaier, C., Sieker, J., & Zarrieß, S. (2025). Can llms ground when they (Don’t) know: A study on direct and loaded political questions. Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 14956–14975. https://doi.org/10.18653/v1/2025.acl-long.728

- Sitter, E., Momen, O., Steig, F., Herrmann, J. B., & Zarrieß, S. (2025). Annotating spatial descriptions in literary and non-literary text. Proceedings of the 19th Linguistic Annotation Workshop (LAW-XIX-2025), 308–325. https://doi.org/10.18653/v1/2025.law-1.26

- Zarrieß, S., Junker, S., Sieker, J., & Alacam, Ö. (2025). Components of creativity: Language model-based predictors for clustering and switching in verbal fluency. Proceedings of the 29th Conference on Computational Natural Language Learning, 216–232. https://doi.org/10.18653/v1/2025.conll-1.15



## Resources

* Code and data on colour classification in Visual Genome: [github](https://github.com/clause-bielefeld/colour-term-grounding)
* ManyNames: We were very happy to collaborate with the [AMORE](https://www.upf.edu/web/amore) group for the collection of this dataset for object naming in real-world images [github](https://github.com/amore-upf/manynames)

<!--
### Image2Latex: Transferring Images into LaTex Code using Deep Learning Methods
__Resources__:
- https://arxiv.org/abs/1908.11415
- https://mathpix.com/

__Contact__: sina.zarrieß@uni-jena.de
-->
